{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b00dae2-c271-4a69-a579-742e084a9058",
   "metadata": {},
   "source": [
    "# Lab | Langchain Evaluation\n",
    "\n",
    "## Intro\n",
    "\n",
    "Pick different sets of data and re-run this notebook. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications.\n",
    "\n",
    "What did you learn? - Let's discuss that in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "## LangChain: Evaluation\n",
    "\n",
    "### Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac75d65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce74685f-50e9-48cf-8e2c-fac05e8e3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.3.75)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.27)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0a5656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-huggingface) (0.3.75)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-huggingface) (0.20.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-huggingface) (0.34.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.27)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.33.4->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e29d2c-ba67-4cba-8ded-375fe040b9ba",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28008949",
   "metadata": {},
   "source": [
    "#### Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import CSVLoader, TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec1106d",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "file = \"D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/OutdoorClothingCatalog_1000.csv\"\n",
    "\n",
    "# Force UTF-8 encoding\n",
    "loader = CSVLoader(file_path=file, encoding=\"utf-8\")\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550eb642-c223-4d78-8f92-0f265ef78b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade --force-reinstall sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc92c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.46.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31c218f",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers\n",
    "\n",
    "\n",
    "# index = VectorstoreIndexCreator(\n",
    "#     vectorstore_cls=DocArrayInMemorySearch,\n",
    "#     embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cpu'})\n",
    "# ).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b8813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317ec576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docarray in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.41.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docarray) (2.3.2)\n",
      "Requirement already satisfied: orjson>=3.8.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docarray) (3.11.3)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docarray) (2.11.7)\n",
      "Requirement already satisfied: rich>=13.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docarray) (14.1.0)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docarray) (2.32.4.20250809)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.10.8->docarray) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.10.8->docarray) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.10.8->docarray) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=13.1.0->docarray) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abhis\\appdata\\roaming\\python\\python313\\site-packages (from rich>=13.1.0->docarray) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
      "Requirement already satisfied: urllib3>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from types-requests>=2.28.11.6->docarray) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect>=0.8.0->docarray) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be5b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers==4.46.0 sympy==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f122e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# # Verify if sentence-transformers is really there\n",
    "# !pip show sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bd97e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.46.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ca2d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.23.0+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.46.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "353c033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abhis\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cpu'})\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e7cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocArrayInMemorySearch\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m      5\u001b[39m index = \u001b[43mVectorstoreIndexCreator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectorstore_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDocArrayInMemorySearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\indexes\\vectorstore.py:218\u001b[39m, in \u001b[36mVectorstoreIndexCreator.from_loaders\u001b[39m\u001b[34m(self, loaders)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m loaders:\n\u001b[32m    217\u001b[39m     docs.extend(loader.load())\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\indexes\\vectorstore.py:244\u001b[39m, in \u001b[36mVectorstoreIndexCreator.from_documents\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a vectorstore index from a list of documents.\u001b[39;00m\n\u001b[32m    236\u001b[39m \n\u001b[32m    237\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m \u001b[33;03m    A `VectorStoreIndexWrapper` containing the constructed vectorstore.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m sub_docs = \u001b[38;5;28mself\u001b[39m.text_splitter.split_documents(documents)\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m vectorstore = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m VectorStoreIndexWrapper(vectorstore=vectorstore)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\vectorstores\\docarray\\in_memory.py:68\u001b[39m, in \u001b[36mDocArrayInMemorySearch.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an DocArrayInMemorySearch store and insert data.\u001b[39;00m\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m \u001b[33;03m    DocArrayInMemorySearch Vector Store\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m store = \u001b[38;5;28mcls\u001b[39m.from_params(embedding, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\vectorstores\\docarray\\base.py:82\u001b[39m, in \u001b[36mDocArrayIndex.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed texts and add to the vector store.\u001b[39;00m\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33;03m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     81\u001b[39m ids: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (t, e) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(texts, embeddings)):\n\u001b[32m     84\u001b[39m     m = metadatas[i] \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:156\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    148\u001b[39m \n\u001b[32m    149\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m \n\u001b[32m    155\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:131\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    138\u001b[39m     msg = (\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgot a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1051\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1048\u001b[39m features.update(extra_features)\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1052\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1053\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1132\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1126\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1127\u001b[39m         module_kwargs = {\n\u001b[32m   1128\u001b[39m             key: value\n\u001b[32m   1129\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1130\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1131\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:234\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m trans_features = {\n\u001b[32m    229\u001b[39m     key: value\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    232\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    236\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1140\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1142\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1155\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    684\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    685\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    686\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         output_attentions,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    624\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    625\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pytorch_utils.py:248\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:639\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# from langchain.indexes import VectorstoreIndexCreator\n",
    "# from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# index = VectorstoreIndexCreator(\n",
    "#     vectorstore_cls=DocArrayInMemorySearch,\n",
    "#     embedding=HuggingFaceEmbeddings(\n",
    "#         model_name=\"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "#         model_kwargs={\"device\": \"cpu\"}\n",
    "#     )\n",
    "# ).from_loaders([loader])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2006054",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ebd73",
   "metadata": {},
   "source": [
    "#### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb04a0f9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/OutdoorClothingCatalog_1000.csv', 'row': 10}, page_content=\": 10\\nname: Cozy Comfort Pullover Set, Stripe\\ndescription: Perfect for lounging, this striped knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out.\\r\\n\\r\\nSize & Fit\\r\\n- Pants are Favorite Fit: Sits lower on the waist.\\r\\n- Relaxed Fit: Our most generous fit sits farthest from the body.\\r\\n\\r\\nFabric & Care\\r\\n- In the softest blend of 63% polyester, 35% rayon and 2% spandex.\\r\\n\\r\\nAdditional Features\\r\\n- Relaxed fit top with raglan sleeves and rounded hem.\\r\\n- Pull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg.\\r\\n\\r\\nImported.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe4a88c2",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/OutdoorClothingCatalog_1000.csv', 'row': 11}, page_content=': 11\\nname: Ultra-Lofty 850 Stretch Down Hooded Jacket\\ndescription: This technical stretch down jacket from our DownTek collection is sure to keep you warm and comfortable with its full-stretch construction providing exceptional range of motion. With a slightly fitted style that falls at the hip and best with a midweight layer, this jacket is suitable for light activity up to 20 and moderate activity up to -30. The soft and durable 100% polyester shell offers complete windproof protection and is insulated with warm, lofty goose down. Other features include welded baffles for a no-stitch construction and excellent stretch, an adjustable hood, an interior media port and mesh stash pocket and a hem drawcord. Machine wash and dry. Imported.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d548aef",
   "metadata": {},
   "source": [
    "#### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106fbd91-f7bc-4d6b-b090-54b6a485ce39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5d5af6-36db-4421-b635-46384e677847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='Yes, the Cozy Comfort Pullover Set is available in multiple colors including gray, navy blue, and black.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set \\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Examples:\\n\"\n",
    "             \"1. Query: Do the Cozy Comfort Pullover Set have side pockets?\\n\"\n",
    "             \"   Answer: Yes\\n\"\n",
    "             \"2. Query: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\\n\"\n",
    "             \"   Answer: The DownTek collection\\n\"\n",
    "             \"Query: {query}\\n\"\n",
    "             \"Answer:\"\n",
    ")\n",
    "\n",
    "# Define the output model\n",
    "class Answer(BaseModel):\n",
    "    answer: str = Field(description=\"The answer to the query\")\n",
    "\n",
    "# Create the output parser\n",
    "class AnswerOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> Answer:\n",
    "        # Split the response to get the answer\n",
    "        answer = text.strip().split(\"Answer:\")[-1].strip()\n",
    "        return Answer(answer=answer)\n",
    "\n",
    "# Initialize the LLM\n",
    "# llm = OpenAI()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Create the LLMChain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_parser=AnswerOutputParser()\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"Is the Cozy Comfort Pullover Set available in different colors?\"\n",
    "\n",
    "# Run the chain\n",
    "result = llm_chain.run({\"query\": query})\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce3e4f",
   "metadata": {},
   "source": [
    "#### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d44f8376",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34e87816",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAGenerateChain(verbose=False, prompt=PromptTemplate(input_variables=['doc'], input_types={}, partial_variables={}, template='You are a teacher coming up with questions to ask on a quiz.\\nGiven the following document, please generate a question and answer based on that document.\\n\\nExample Format:\\n<Begin Document>\\n...\\n<End Document>\\nQUESTION: question here\\nANSWER: answer here\\n\\nThese questions should be detailed and be based explicitly on information in the document. Begin!\\n\\n<Begin Document>\\n{doc}\\n<End Document>'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000157DE65F490>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000157DE65E190>, root_client=<openai.OpenAI object at 0x00000157DE65FE10>, root_async_client=<openai.AsyncOpenAI object at 0x00000157DE65F230>, model_kwargs={}, openai_api_key=SecretStr('**********')), llm_kwargs={})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())\n",
    "\n",
    "example_gen_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acb34772-368f-4b5e-b4bd-da9b637cc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62abae09",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_7536\\3125874183.py:1: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  new_examples = example_gen_chain.apply_and_parse(\n"
     ]
    }
   ],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97ab28b5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qa_pairs': {'query': \"What is the approximate weight of one pair of Women's Campside Oxfords?\",\n",
       "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ebe4228",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/OutdoorClothingCatalog_1000.csv', 'row': 0}, page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\r\\n\\r\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\r\\n\\r\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\r\\n\\r\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\r\\n\\r\\nQuestions? Please contact us for any inquiries.\")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7693fe86-feeb-4d73-b400-e66e79315274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': \"What is the approximate weight of one pair of Women's Campside Oxfords?\",\n",
       "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?',\n",
       "  'answer': 'The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\",\n",
       "  'answer': \"The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\"},\n",
       " {'query': 'What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.'},\n",
       " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
       "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_flattened = [data['qa_pairs'] for data in new_examples]\n",
    "d_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf25f2f",
   "metadata": {},
   "source": [
    "#### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ada2a3fc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examples += new_example\n",
    "examples += d_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2184b9d7-22ab-43a5-9ba5-b27fef024874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do the Cozy Comfort Pullover Set         have side pockets?',\n",
       " 'answer': 'Yes'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cdf5cf5",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Do the Cozy Comfort Pullover Set         have side pockets?',\n",
       " 'result': 'Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3cb08",
   "metadata": {},
   "source": [
    "### Manual Evaluation - Fun part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcaf622e",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a142638",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Do the Cozy Comfort Pullover Set         have side pockets?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Do the Cozy Comfort Pullover Set         have side pockets?\",\n",
      "  \"context\": \"Side seam pockets and back zip pocket, with mesh insert for quick drainage.<<<<>>>>>Two elastic mesh water bottle pockets.\\r\\nTop compartment includes pocket with double-seal zipper for quick access.\\r\\nSide<<<<>>>>>All pockets have sturdy pocket bags and offer plenty of room for a wallet, cell phone and more.\\r\\n\\r\\nGusseted crotch for ease of movement.\\r\\n\\r\\nImported.<<<<>>>>>Two elastic mesh water bottle pockets.\\r\\nTop compartment includes pocket with double-se\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the user's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nSide seam pockets and back zip pocket, with mesh insert for quick drainage.<<<<>>>>>Two elastic mesh water bottle pockets.\\r\\nTop compartment includes pocket with double-seal zipper for quick access.\\r\\nSide<<<<>>>>>All pockets have sturdy pocket bags and offer plenty of room for a wallet, cell phone and more.\\r\\n\\r\\nGusseted crotch for ease of movement.\\r\\n\\r\\nImported.<<<<>>>>>Two elastic mesh water bottle pockets.\\r\\nTop compartment includes pocket with double-se\\nHuman: Do the Cozy Comfort Pullover Set         have side pockets?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [2.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 54,\n",
      "                \"prompt_tokens\": 157,\n",
      "                \"total_tokens\": 211,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-CDtGLwDc1eEteoB67oNseA9T8Lshx\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--4c36ef63-ec73-44c8-b8af-6afb4229c78a-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 157,\n",
      "              \"output_tokens\": 54,\n",
      "              \"total_tokens\": 211,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 54,\n",
      "      \"prompt_tokens\": 157,\n",
      "      \"total_tokens\": 211,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-CDtGLwDc1eEteoB67oNseA9T8Lshx\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [2.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [2.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [2.03s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Do the Cozy Comfort Pullover Set         have side pockets?',\n",
       " 'result': 'Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3d6bef0",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdbdce",
   "metadata": {},
   "source": [
    "### LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a54769b0-3daf-4cac-b259-89a10dd9b5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples += d_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ea95385-1b4c-440a-9fea-8500b4cc2154",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Do the Cozy Comfort Pullover Set         have side pockets?',\n",
       "  'answer': 'Yes'},\n",
       " {'query': 'What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?',\n",
       "  'answer': 'The DownTek collection'},\n",
       " {'query': \"What is the approximate weight of one pair of Women's Campside Oxfords?\",\n",
       "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?',\n",
       "  'answer': 'The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\",\n",
       "  'answer': \"The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\"},\n",
       " {'query': 'What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.'},\n",
       " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
       "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.'},\n",
       " {'query': \"What is the approximate weight of one pair of Women's Campside Oxfords?\",\n",
       "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?',\n",
       "  'answer': 'The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\",\n",
       "  'answer': \"The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\"},\n",
       " {'query': 'What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.'},\n",
       " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
       "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4dca05a",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae7e8b4e-4468-4048-8544-c9936704ea93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Do the Cozy Comfort Pullover Set         have side pockets?',\n",
       "  'answer': 'Yes',\n",
       "  'result': 'Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.'},\n",
       " {'query': 'What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?',\n",
       "  'answer': 'The DownTek collection',\n",
       "  'result': 'The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.'},\n",
       " {'query': \"What is the approximate weight of one pair of Women's Campside Oxfords?\",\n",
       "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\",\n",
       "  'result': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?',\n",
       "  'answer': 'The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".',\n",
       "  'result': 'The dimensions of the small size of the Recycled Waterhog Dog Mat are 18\" x 28\", and the dimensions of the medium size are 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\",\n",
       "  'answer': \"The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\",\n",
       "  'result': \"The Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offers the following features according to the document:\\n- Bright colors, ruffles, and exclusive whimsical prints\\n- Four-way-stretch and chlorine-resistant fabric\\n- UPF 50+ rated fabric for sun protection\\n- Crossover no-slip straps\\n- Fully lined bottom for secure fit and maximum coverage\\n- Machine wash and line dry for best results\"},\n",
       " {'query': 'What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.',\n",
       "  'result': 'The Refresh Swimwear, V-Neck Tankini Contrasts is made of 82% recycled nylon with 18% Lycra spandex for the body, and 90% recycled nylon with 10% Lycra spandex for the lining.'},\n",
       " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
       "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.',\n",
       "  'result': 'The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which offers exceptional breathability, making them ideal for various outdoor activities year-round.'},\n",
       " {'query': \"What is the approximate weight of one pair of Women's Campside Oxfords?\",\n",
       "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\",\n",
       "  'result': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"},\n",
       " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?',\n",
       "  'answer': 'The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".',\n",
       "  'result': 'The dimensions of the small size of the Recycled Waterhog Dog Mat are 18\" x 28\", and the dimensions of the medium size are 22.5\" x 34.5\".'},\n",
       " {'query': \"What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\",\n",
       "  'answer': \"The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\",\n",
       "  'result': \"The Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offers the following features according to the document:\\n- Bright colors, ruffles, and exclusive whimsical prints\\n- Four-way-stretch and chlorine-resistant fabric\\n- UPF 50+ rated fabric for sun protection\\n- Crossover no-slip straps\\n- Fully lined bottom for secure fit and maximum coverage\\n- Machine wash and line dry for best results\"},\n",
       " {'query': 'What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?',\n",
       "  'answer': 'The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.',\n",
       "  'result': 'The fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts is as follows:\\n- Body: 82% recycled nylon with 18% Lycra spandex\\n- Lining: 90% recycled nylon with 10% Lycra spandex'},\n",
       " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
       "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.',\n",
       "  'result': 'The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which offers exceptional breathability, keeping you dry and comfortable during various outdoor activities in any weather condition.'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6012a3e0",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "724b1c0b",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b46ae55",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc42eb35-c2d7-4581-8004-d315ade63eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': 'INCORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'},\n",
       " {'results': 'CORRECT'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3437cfbe",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: Do the Cozy Comfort Pullover Set         have side pockets?\n",
      "Real Answer: Yes\n",
      "Predicted Answer: Based on the provided context, the Cozy Comfort Pullover Set does not have side pockets. It has side seam pockets, a back zip pocket, two elastic mesh water bottle pockets, and a top compartment with a pocket with a double-seal zipper for quick access.\n",
      "\n",
      "Example 1:\n",
      "Question: What collection is the Ultra-Lofty         850 Stretch Down Hooded Jacket from?\n",
      "Real Answer: The DownTek collection\n",
      "Predicted Answer: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.\n",
      "\n",
      "Example 2:\n",
      "Question: What is the approximate weight of one pair of Women's Campside Oxfords?\n",
      "Real Answer: The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\n",
      "Predicted Answer: The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\n",
      "\n",
      "Example 3:\n",
      "Question: What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?\n",
      "Real Answer: The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".\n",
      "Predicted Answer: The dimensions of the small size of the Recycled Waterhog Dog Mat are 18\" x 28\", and the dimensions of the medium size are 22.5\" x 34.5\".\n",
      "\n",
      "Example 4:\n",
      "Question: What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\n",
      "Real Answer: The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\n",
      "Predicted Answer: The Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offers the following features according to the document:\n",
      "- Bright colors, ruffles, and exclusive whimsical prints\n",
      "- Four-way-stretch and chlorine-resistant fabric\n",
      "- UPF 50+ rated fabric for sun protection\n",
      "- Crossover no-slip straps\n",
      "- Fully lined bottom for secure fit and maximum coverage\n",
      "- Machine wash and line dry for best results\n",
      "\n",
      "Example 5:\n",
      "Question: What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?\n",
      "Real Answer: The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.\n",
      "Predicted Answer: The Refresh Swimwear, V-Neck Tankini Contrasts is made of 82% recycled nylon with 18% Lycra spandex for the body, and 90% recycled nylon with 10% Lycra spandex for the lining.\n",
      "\n",
      "Example 6:\n",
      "Question: What is the main feature of the EcoFlex 3L Storm Pants?\n",
      "Real Answer: The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.\n",
      "Predicted Answer: The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which offers exceptional breathability, making them ideal for various outdoor activities year-round.\n",
      "\n",
      "Example 7:\n",
      "Question: What is the approximate weight of one pair of Women's Campside Oxfords?\n",
      "Real Answer: The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\n",
      "Predicted Answer: The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\n",
      "\n",
      "Example 8:\n",
      "Question: What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?\n",
      "Real Answer: The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".\n",
      "Predicted Answer: The dimensions of the small size of the Recycled Waterhog Dog Mat are 18\" x 28\", and the dimensions of the medium size are 22.5\" x 34.5\".\n",
      "\n",
      "Example 9:\n",
      "Question: What features does the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offer according to the document?\n",
      "Real Answer: The toddler's two-piece swimsuit features bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage. It is recommended to machine wash and line dry for best results.\n",
      "Predicted Answer: The Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece offers the following features according to the document:\n",
      "- Bright colors, ruffles, and exclusive whimsical prints\n",
      "- Four-way-stretch and chlorine-resistant fabric\n",
      "- UPF 50+ rated fabric for sun protection\n",
      "- Crossover no-slip straps\n",
      "- Fully lined bottom for secure fit and maximum coverage\n",
      "- Machine wash and line dry for best results\n",
      "\n",
      "Example 10:\n",
      "Question: What is the fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts?\n",
      "Real Answer: The body of the tankini top is made of 82% recycled nylon and 18% Lycra spandex, while the lining is 90% recycled nylon and 10% Lycra spandex. The fabric is breathable, quick drying, abrasion resistant, and has a UPF 50+ sun protection rating.\n",
      "Predicted Answer: The fabric makeup of the Refresh Swimwear, V-Neck Tankini Contrasts is as follows:\n",
      "- Body: 82% recycled nylon with 18% Lycra spandex\n",
      "- Lining: 90% recycled nylon with 10% Lycra spandex\n",
      "\n",
      "Example 11:\n",
      "Question: What is the main feature of the EcoFlex 3L Storm Pants?\n",
      "Real Answer: The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested.\n",
      "Predicted Answer: The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which offers exceptional breathability, keeping you dry and comfortable during various outdoor activities in any weather condition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    # print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d127a-a9e3-465d-a8ae-0e2c4b4a2659",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "One can also easily evaluate your QA chains with the metrics offered in ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5ef0493-34ff-4801-b405-69c76ce86c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_7536\\1211385726.py:7: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
      "  index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cpu'})).from_loaders([loader])\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt\", encoding = 'utf-8')\n",
    "\n",
    "\n",
    "index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cpu'})).from_loaders([loader])\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature= 0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0449cae-de25-4ef6-ae64-78ccf5e06a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York City was originally named New Amsterdam by Dutch colonists in 1626. However, in 1664, the city came under British control and was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city has been continuously named New York since November 1674.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing it out\n",
    "\n",
    "question = \"How did New York City get its name?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e846b3d-f79f-46eb-8075-c816268c0500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How did New York City get its name?',\n",
       " 'result': 'New York City was originally named New Amsterdam by Dutch colonists in 1626. However, in 1664, the city came under British control and was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city has been continuously named New York since November 1674.',\n",
       " 'source_documents': [Document(id='7240e949-b8b7-417d-b73a-34ff5285b1e4', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content='The city and its metropolitan area constitute the premier gateway for legal immigration to the United States. As many as 800 languages are spoken in New York, making it the most linguistically diverse city in the world. New York City is home to more than 3.2 million residents born outside the U.S., the largest foreign-born population of any city in the world as of 2016.New York City traces its origins to a trading post founded on the southern tip of Manhattan Island by Dutch colonists in approximately 1624. The settlement was named New Amsterdam (Dutch: Nieuw Amsterdam) in 1626 and was chartered as a city in 1653. The city came under British control in 1664 and was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York. The city was regained by the Dutch in July 1673 and was renamed New Orange for one year and three months; the city has been continuously named New York since November 1674. New York City was the capital of the United States'),\n",
       "  Document(id='bd579ded-6116-4d7c-a4e3-2aad6878059d', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content='New York City has been a metropolitan municipality with a Strong mayorcouncil form of government since its consolidation in 1898. In New York City, the city government is responsible for public education, correctional institutions, public safety, recreational facilities, sanitation, water supply, and welfare services.'),\n",
       "  Document(id='00cef4d0-9e4f-4cf0-a69b-fcb9fcff709d', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"Despite New York's heavy reliance on its vast public transit system, streets are a defining feature of the city. The Commissioners' Plan of 1811 greatly influenced the city's physical development. Several of the city's streets and avenues, including Broadway, Wall Street, Madison Avenue, and Seventh Avenue are also used as metonyms for national industries there: the theater, finance, advertising, and fashion organizations, respectively.\"),\n",
       "  Document(id='8516431b-3424-4f22-b351-b2ed91fe0e76', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"In the pre-Columbian era, the area of present-day New York City was inhabited by Algonquian Native Americans, including the Lenape. Their homeland, known as Lenapehoking, included the present-day areas of Staten Island, Manhattan, the Bronx, the western portion of Long Island (including the areas that would later become the boroughs of Brooklyn and Queens), and the Lower Hudson Valley.The first documented visit into New York Harbor by a European was in 1524 by Italian Giovanni da Verrazzano, an explorer from Florence in the service of the French crown. He claimed the area for France and named it Nouvelle Angoulme (New Angoulme). A Spanish expedition, led by the Portuguese captain Estvo Gomes sailing for Emperor Charles V, arrived in New York Harbor in January 1525 and charted the mouth of the Hudson River, which he named Ro de San Antonio ('Saint Anthony's River'). The Padrn Real of 1527, the first scientific map to show the East Coast of North America continuously, was informed\")]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9da8-a593-4fc6-9d4b-fea2af6bdfd0",
   "metadata": {},
   "source": [
    "Now in order to evaluate the qa system we generated a few relevant questions. We've generated a few question for you but feel free to add any you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2e2cade-0005-41c1-b775-c6a7175bcf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What is the population of New York City as of 2020?\",\n",
    "    \"Which borough of New York City has the highest population?\",\n",
    "    \"What is the economic significance of New York City?\",\n",
    "    \"How did New York City get its name?\",\n",
    "    \"What is the significance of the Statue of Liberty in New York City?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"8,804,190\",\n",
    "    \"Brooklyn\",\n",
    "    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n",
    "    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n",
    "    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truths\": [eval_answers[i]]}\n",
    "    for i, q in enumerate(eval_questions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aac9358e-f8bc-4992-aea3-c83160ff0ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the population of New York City as of 2020?',\n",
       "  'ground_truths': ['8,804,190']},\n",
       " {'query': 'Which borough of New York City has the highest population?',\n",
       "  'ground_truths': ['Brooklyn']},\n",
       " {'query': 'What is the economic significance of New York City?',\n",
       "  'ground_truths': [\"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\"]},\n",
       " {'query': 'How did New York City get its name?',\n",
       "  'ground_truths': ['New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.']},\n",
       " {'query': 'What is the significance of the Statue of Liberty in New York City?',\n",
       "  'ground_truths': ['The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.']}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21efe8-7c30-449a-9b8e-5b79778e305b",
   "metadata": {},
   "source": [
    "#### Introducing RagasEvaluatorChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c2214-a6eb-4d4f-9403-7e1574b97a36",
   "metadata": {},
   "source": [
    "`RagasEvaluatorChain` creates a wrapper around the metrics ragas provides (documented [here](https://github.com/explodinggradients/ragas/blob/main/docs/metrics.md)), making it easier to run these evaluation with langchain and langsmith.\n",
    "\n",
    "The evaluator chain has the following APIs\n",
    "\n",
    "- `__call__()`: call the `RagasEvaluatorChain` directly on the result of a QA chain.\n",
    "- `evaluate()`: evaluate on a list of examples (with the input queries) and predictions (outputs from the QA chain). \n",
    "- `evaluate_run()`: method implemented that is called by langsmith evaluators to evaluate langsmith datasets.\n",
    "\n",
    "lets see each of them in action to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "022c8aae-fe5f-4274-b638-9209151b9491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manhattan (New York County) has the highest population density of any borough in New York City.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain.invoke({\"query\": eval_questions[1]})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eae31c80-42c9-4b1f-95b3-c05ceadb103f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"query\": \"question\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\"\n",
    "}\n",
    "\n",
    "result_updated = {}\n",
    "for old_key, new_key in key_mapping.items():\n",
    "    if old_key in result:\n",
    "        result_updated[new_key] = result[old_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ecd4dd9f-16d7-43d4-ac8e-6c5aa5e3f7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which borough of New York City has the highest population?',\n",
       " 'answer': 'Manhattan (New York County) has the highest population density of any borough in New York City.',\n",
       " 'contexts': [Document(id='738455bd-0526-46c0-bd95-25e0bdeeb030', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"New York City is the most populous city in the United States, with 8,804,190 residents incorporating more immigration into the city than outmigration since the 2010 United States census. More than twice as many people live in New York City as compared to Los Angeles, the second-most populous U.S. city; and New York has more than three times the population of Chicago, the third-most populous U.S. city. New York City gained more residents between 2010 and 2020 (629,000) than any other U.S. city, and a greater amount than the total sum of the gains over the same decade of the next four largest U.S. cities, Los Angeles, Chicago, Houston, and Phoenix, Arizona combined. New York City's population is about 44% of New York State's population, and about 39% of the population of the New York metropolitan area. The majority of New York City residents in 2020 (5,141,538, or 58.4%) were living on Long Island, in Brooklyn, or in Queens. The New York City metropolitan statistical area, has the\"),\n",
       "  Document(id='ffbbbdd7-a443-4720-a249-faa3a845bf00', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"New York, often called New York City or NYC, is the most populous city in the United States. With a 2020 population of 8,804,190 distributed over 300.46 square miles (778.2 km2), New York City is the most densely populated major city in the United States and more than twice as populous as Los Angeles, the nation's second-largest city. New York City is located at the southern tip of New York State. It constitutes the geographical and demographic center of both the Northeast megalopolis and the New York metropolitan area, the largest metropolitan area in the U.S. by both population and urban area. With over 20.1 million people in its metropolitan statistical area and 23.5 million in its combined statistical area as of 2020, New York is one of the world's most populous megacities, and over 58 million people live within 250 mi (400 km) of the city. New York City is a global cultural, financial, entertainment, and media center with a significant influence on commerce, health care and life\"),\n",
       "  Document(id='9d052362-55f4-49f4-bc72-706f878d6d62', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"Manhattan (New York County) is the geographically smallest and most densely populated borough. It is home to Central Park and most of the city's skyscrapers, and is sometimes locally known as The City. Manhattan's population density of 72,033 people per square mile (27,812/km2) in 2015 makes it the highest of any county in the United States and higher than the density of any individual American city.Manhattan is the cultural, administrative, and financial center of New York City and contains the headquarters of many major multinational corporations, the United Nations headquarters, Wall Street, and a number of important universities. The borough of Manhattan is often described as the financial and cultural center of the world.Most of the borough is situated on Manhattan Island, at the mouth of the Hudson River and the East River, and its southern tip, at the confluence of the two rivers, represents the birthplace of New York City itself. Several small islands also compose part of the\"),\n",
       "  Document(id='aa022fe9-e7e9-4154-94d1-41ea8fc8a702', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"=== Population density ===\\n\\nIn 2020, the city had an estimated population density of 29,302.37 inhabitants per square mile (11,313.71/km2), rendering it the nation's most densely populated of all larger municipalities (those with more than 100,000 residents), with several small cities (of fewer than 100,000) in adjacent Hudson County, New Jersey having greater density, as per the 2010 census. Geographically co-extensive with New York County, the borough of Manhattan's 2017 population density of 72,918 inhabitants per square mile (28,154/km2) makes it the highest of any county in the United States and higher than the density of any individual American city. The next three densest counties in the United States, placing second through fourth, are also New York boroughs: Brooklyn, the Bronx, and Queens respectively.\\n\\n\\n=== Race and ethnicity ===\")]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00d5cc30-d25e-41bd-8695-9246b73938bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: recordclass in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir recordclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "775d55d9-437d-40c4-bb5f-87c7b65fa567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas==0.1.9 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (2.3.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (0.11.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (0.3.75)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (0.3.29)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (0.3.32)\n",
      "Requirement already satisfied: openai>1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (1.107.0)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (0.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\abhis\\appdata\\roaming\\python\\python313\\site-packages (from ragas==0.1.9) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.1.9) (1.4.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai>1->ragas==0.1.9) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.9) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.9) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.9) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.1.9) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.9) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.9) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai>1->ragas==0.1.9) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (2.32.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (0.34.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets->ragas==0.1.9) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas==0.1.9) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets->ragas==0.1.9) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets->ragas==0.1.9) (2.5.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain->ragas==0.1.9) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain->ragas==0.1.9) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain->ragas==0.1.9) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core->ragas==0.1.9) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core->ragas==0.1.9) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas==0.1.9) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.1.9) (3.2.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas==0.1.9) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas==0.1.9) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas==0.1.9) (0.24.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community->ragas==0.1.9) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community->ragas==0.1.9) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community->ragas==0.1.9) (0.4.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas==0.1.9) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas==0.1.9) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas==0.1.9) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas==0.1.9) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken->ragas==0.1.9) (2025.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abhis\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets->ragas==0.1.9) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets->ragas==0.1.9) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets->ragas==0.1.9) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.1.9) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884125fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ragas.integrations.langchain import EvaluatorChain\n",
    "# # from ragas import evaluate\n",
    "# from ragas.metrics import (\n",
    "#     faithfulness,\n",
    "#     answer_relevancy,\n",
    "#     context_relevancy,\n",
    "#     context_recall,\n",
    "# )\n",
    "# # create evaluation chains\n",
    "# faithfulness_chain   = EvaluatorChain(metric=faithfulness)\n",
    "# answer_rel_chain     = EvaluatorChain(metric=answer_relevancy)\n",
    "# context_rel_chain    = EvaluatorChain(metric=context_relevancy)\n",
    "# context_recall_chain = EvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "29b14c07-bf6c-4e86-ad1a-2a6c4d1a509d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain \n",
    "# from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain   = EvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain     = EvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain    = EvaluatorChain(metric=context_relevancy)\n",
    "context_recall_chain = EvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8b636-d738-41bd-ac68-21cce2c4b720",
   "metadata": {},
   "source": [
    "1. `__call__()`\n",
    "\n",
    "Directly run the evaluation chain with the results from the QA chain. Do note that metrics like context_relevancy and faithfulness require the `source_documents` to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7815671c-1fc8-46ba-8356-4a0bd5558530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which borough of New York City has the highest population?',\n",
       " 'result': 'Manhattan (New York County) has the highest population density of any borough in New York City.',\n",
       " 'source_documents': [Document(id='738455bd-0526-46c0-bd95-25e0bdeeb030', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"New York City is the most populous city in the United States, with 8,804,190 residents incorporating more immigration into the city than outmigration since the 2010 United States census. More than twice as many people live in New York City as compared to Los Angeles, the second-most populous U.S. city; and New York has more than three times the population of Chicago, the third-most populous U.S. city. New York City gained more residents between 2010 and 2020 (629,000) than any other U.S. city, and a greater amount than the total sum of the gains over the same decade of the next four largest U.S. cities, Los Angeles, Chicago, Houston, and Phoenix, Arizona combined. New York City's population is about 44% of New York State's population, and about 39% of the population of the New York metropolitan area. The majority of New York City residents in 2020 (5,141,538, or 58.4%) were living on Long Island, in Brooklyn, or in Queens. The New York City metropolitan statistical area, has the\"),\n",
       "  Document(id='ffbbbdd7-a443-4720-a249-faa3a845bf00', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"New York, often called New York City or NYC, is the most populous city in the United States. With a 2020 population of 8,804,190 distributed over 300.46 square miles (778.2 km2), New York City is the most densely populated major city in the United States and more than twice as populous as Los Angeles, the nation's second-largest city. New York City is located at the southern tip of New York State. It constitutes the geographical and demographic center of both the Northeast megalopolis and the New York metropolitan area, the largest metropolitan area in the U.S. by both population and urban area. With over 20.1 million people in its metropolitan statistical area and 23.5 million in its combined statistical area as of 2020, New York is one of the world's most populous megacities, and over 58 million people live within 250 mi (400 km) of the city. New York City is a global cultural, financial, entertainment, and media center with a significant influence on commerce, health care and life\"),\n",
       "  Document(id='9d052362-55f4-49f4-bc72-706f878d6d62', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"Manhattan (New York County) is the geographically smallest and most densely populated borough. It is home to Central Park and most of the city's skyscrapers, and is sometimes locally known as The City. Manhattan's population density of 72,033 people per square mile (27,812/km2) in 2015 makes it the highest of any county in the United States and higher than the density of any individual American city.Manhattan is the cultural, administrative, and financial center of New York City and contains the headquarters of many major multinational corporations, the United Nations headquarters, Wall Street, and a number of important universities. The borough of Manhattan is often described as the financial and cultural center of the world.Most of the borough is situated on Manhattan Island, at the mouth of the Hudson River and the East River, and its southern tip, at the confluence of the two rivers, represents the birthplace of New York City itself. Several small islands also compose part of the\"),\n",
       "  Document(id='aa022fe9-e7e9-4154-94d1-41ea8fc8a702', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"=== Population density ===\\n\\nIn 2020, the city had an estimated population density of 29,302.37 inhabitants per square mile (11,313.71/km2), rendering it the nation's most densely populated of all larger municipalities (those with more than 100,000 residents), with several small cities (of fewer than 100,000) in adjacent Hudson County, New Jersey having greater density, as per the 2010 census. Geographically co-extensive with New York County, the borough of Manhattan's 2017 population density of 72,918 inhabitants per square mile (28,154/km2) makes it the highest of any county in the United States and higher than the density of any individual American city. The next three densest counties in the United States, placing second through fourth, are also New York boroughs: Brooklyn, the Bronx, and Queens respectively.\\n\\n\\n=== Race and ethnicity ===\")]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck the result that we are going to validate.\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdd07c-956c-458f-8844-e056f29e3c83",
   "metadata": {},
   "source": [
    "**Faithfulness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d41c6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['question', 'answer', 'contexts'])\n",
      "question : Which borough of New York City has the highest population?\n",
      "answer : Manhattan (New York County) has the highest population density of any borough in New York City.\n",
      "contexts : [Document(id='738455bd-0526-46c0-bd95-25e0bdeeb030', metadata={'source': 'D:/Ironhack/Week 8/DAY 2/lab-langchain-evaluation/data/nyc_text.txt'}, page_content=\"New York City is the most populous city in the United States, with 8,804,190 residents incorporating more immigration into the city than outmigration since the 2010 United States census. More than twice as many people live in New York City as compared to Los Angeles, the second-most populous U.S. city; and New York has more than three time\n"
     ]
    }
   ],
   "source": [
    "print(result_updated.keys())  # See what keys are in the dict\n",
    "for k, v in result_updated.items():\n",
    "    print(k, \":\", str(v)[:500])  # Print first 500 chars or so of each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "783bbea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "# Replace Documents with their text content inside the 'contexts' list\n",
    "result_updated[\"contexts\"] = [\n",
    "    doc.page_content if hasattr(doc, \"page_content\") else str(doc)\n",
    "    for doc in result_updated[\"contexts\"]\n",
    "]\n",
    "# Now run the async faithfulness_chain\n",
    "result = faithfulness_chain(result_updated)\n",
    "print(result[\"faithfulness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "304f5f0f-a237-4584-becb-a35607caf26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = faithfulness_chain(result_updated)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd78a9-d7c5-42a0-8705-4c544ec6408e",
   "metadata": {},
   "source": [
    "High faithfulness_score means that there are exact consistency between the source documents and the answer.\n",
    "\n",
    "You can check lower faithfulness scores by changing the result (answer from LLM) or source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "15f42b97-a84f-4015-9da5-fa3b0b703c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_result = result.copy()\n",
    "fake_result[\"result\"] = \"we are the champions\"\n",
    "eval_result = faithfulness_chain(fake_result)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02348380-159a-4578-a95e-493cdcfcebe7",
   "metadata": {},
   "source": [
    "**Context Relevancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "291023f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "input_for_context_recall = {\n",
    "    \"ground_truth\": result[\"answer\"],  # or some other ground truth text\n",
    "    \"contexts\": result[\"contexts\"],   # if needed by your chain\n",
    "    \"question\": result[\"question\"],   # if needed\n",
    "    # add other keys your chain expects\n",
    "}\n",
    "eval_result = context_recall_chain(input_for_context_recall)\n",
    "print(eval_result[\"context_recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0fd2fb9e-19d1-4cf6-9773-897546c2d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_result = context_recall_chain(result)\n",
    "# eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118cba80-c2a3-408e-9d8d-857521cbe723",
   "metadata": {},
   "source": [
    "High context_recall_score means that the ground truth is present in the source documents.\n",
    "\n",
    "You can check lower context recall scores by changing the source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8235dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Prepare input for the chain\n",
    "fake_result = {\n",
    "    \"ground_truth\": \"I love Christmas\",  # required key\n",
    "    \"question\": result.get(\"question\", \"What is the question?\"),  # optional, if your chain expects it\n",
    "    \"source_documents\": [Document(page_content=\"I love christmas\")],\n",
    "    \"contexts\": result.get(\"contexts\", [])  # optional, if your chain expects it\n",
    "}\n",
    "\n",
    "# Call the chain\n",
    "eval_result = context_recall_chain(fake_result)\n",
    "\n",
    "# Access output\n",
    "print(eval_result[\"context_recall\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc06403-c514-47fd-ac82-d95ece8d2f06",
   "metadata": {},
   "source": [
    "2. `evaluate()`\n",
    "\n",
    "Evaluate a list of inputs/queries and the outputs/predictions from the QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40038e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "\n",
    "# run the queries as a batch for efficiency\n",
    "predictions = qa_chain.batch(examples)\n",
    "\n",
    "# prepare data for ragas.evaluate\n",
    "# Ragas expects a Dataset with columns 'question', 'answer', 'contexts', and 'ground_truths'\n",
    "# We need to align the examples and predictions to create this Dataset\n",
    "\n",
    "# Create a list of dictionaries with the required keys\n",
    "ragas_data = []\n",
    "for i in range(len(examples)):\n",
    "    ragas_data.append({\n",
    "        'question': examples[i]['query'],\n",
    "        'ground_truths': examples[i]['ground_truths'],\n",
    "        'answer': predictions[i]['result'],\n",
    "        'contexts': [doc.page_content for doc in predictions[i]['source_documents'] if isinstance(doc, Document)] # Ensure contexts are strings\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries to a Dataset\n",
    "dataset = Dataset.from_list(ragas_data)\n",
    "\n",
    "# evaluate\n",
    "print(\"evaluating...\")\n",
    "r = evaluate(dataset, metrics=[faithfulness])\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
